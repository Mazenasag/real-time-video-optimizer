{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8a01c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "76048337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e:\\\\Mlop\\\\End to end\\\\real-time-video-optimizer'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fad611fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1b8579c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"data/raw/network_data.csv\",parse_dates=['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b49b41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81fa1f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# class MachineLearning:\n",
    "#     def __init__(self):\n",
    "#         \"\"\"\n",
    "#         Initialize the MachineLearning class.\n",
    "#         \"\"\"\n",
    "#         self.models = {\n",
    "#             'linear_regression': LinearRegression(),\n",
    "#             'random_forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "#         }\n",
    "\n",
    "#     def load_data(self, filepath):\n",
    "#         \"\"\"\n",
    "#         Load data from a CSV file.\n",
    "        \n",
    "#         :param filepath: str, path to the CSV file\n",
    "#         :return: DataFrame, loaded data\n",
    "#         \"\"\"\n",
    "#         return pd.read_csv(filepath, parse_dates=['timestamp'])\n",
    "\n",
    "#     def preprocess_data(self, data):\n",
    "#         \"\"\"\n",
    "#         Preprocess the data for training.\n",
    "        \n",
    "#         :param data: DataFrame, input data\n",
    "#         :return: DataFrame, preprocessed data\n",
    "#         \"\"\"\n",
    "#         data['hour'] = data['timestamp'].dt.hour\n",
    "#         data['day'] = data['timestamp'].dt.day\n",
    "#         data['weekday'] = data['timestamp'].dt.weekday\n",
    "#         data['month'] = data['timestamp'].dt.month\n",
    "#         data = data.drop(columns=['timestamp'])\n",
    "#         # Convert categorical variables to numerical\n",
    "#         data = pd.get_dummies(data, columns=['network_type', 'device_type'], drop_first=True)\n",
    "#         # Fill missing values\n",
    "#         data = data.fillna(data.mean(numeric_only=True))\n",
    "#         return data\n",
    "\n",
    "#     def split_data(self, data, target_column, test_size=0.2):\n",
    "#         \"\"\"\n",
    "#         Split the data into training and testing sets.\n",
    "        \n",
    "#         :param data: DataFrame, input data\n",
    "#         :param target_column: str, name of the target column\n",
    "#         :param test_size: float, proportion of the data to include in the test split\n",
    "#         :return: tuple, training and testing sets\n",
    "#         \"\"\"\n",
    "#         X = data.drop(columns=[target_column])\n",
    "#         y = data[target_column]\n",
    "#         X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "#         return X_train, X_test, y_train, y_test\n",
    "\n",
    "#     def train_model(self, model_name, X_train, y_train):\n",
    "#         \"\"\"\n",
    "#         Train the specified model.\n",
    "        \n",
    "#         :param model_name: str, name of the model to train\n",
    "#         :param X_train: DataFrame, training features\n",
    "#         :param y_train: Series, training target\n",
    "#         :return: trained model\n",
    "#         \"\"\"\n",
    "#         model = self.models.get(model_name)\n",
    "#         if model is not None:\n",
    "#             model.fit(X_train, y_train)\n",
    "#             return model\n",
    "#         else:\n",
    "#             raise ValueError(f\"Model {model_name} not found.\")\n",
    "\n",
    "\n",
    "#     def evaluate_model(self, model, X_test, y_test):\n",
    "#         \"\"\"\n",
    "#         Evaluate the specified model using various metrics.\n",
    "        \n",
    "#         :param model: trained model\n",
    "#         :param X_test: DataFrame, testing features\n",
    "#         :param y_test: Series, testing target\n",
    "#         :return: dict, evaluation metrics\n",
    "#         \"\"\"\n",
    "#         y_pred = model.predict(X_test)\n",
    "#         metrics = {\n",
    "#             'mae': mean_absolute_error(y_test, y_pred),\n",
    "#             'rmse': np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "#         }\n",
    "#         return metrics\n",
    "\n",
    "#     def save_model(self, model_name, filepath):\n",
    "#         \"\"\"\n",
    "#         Save the trained model to a file.\n",
    "        \n",
    "#         :param model_name: str, name of the model to save\n",
    "#         :param filepath: str, path to save the model\n",
    "#         \"\"\"\n",
    "#         model = self.models.get(model_name)\n",
    "#         if model is None:\n",
    "#             raise ValueError(f\"Model {model_name} not found.\")\n",
    "#         joblib.dump(model, filepath)\n",
    "\n",
    "#     def load_model(self, model_name, filepath):\n",
    "#         \"\"\"\n",
    "#         Load a trained model from a file.\n",
    "        \n",
    "#         :param model_name: str, name to assign to the loaded model\n",
    "#         :param filepath: str, path to the saved model\n",
    "#         \"\"\"\n",
    "#         self.models[model_name] = joblib.load(filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1c828230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data['bandwidth'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6d4ea55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == \"__main__\":\n",
    "#     data_filepath = 'data/raw/network_data.csv'\n",
    "#     target_column = 'bandwidth'\n",
    "\n",
    "#     ml = MachineLearning()\n",
    "#     data = ml.load_data(data_filepath)\n",
    "#     data = ml.preprocess_data(data)\n",
    "#     X_train, X_test, y_train, y_test = ml.split_data(data, target_column)\n",
    "\n",
    "#     # Train and evaluate linear regression model\n",
    "#     lr_model = ml.train_model('linear_regression', X_train, y_train)\n",
    "#     lr_metrics = ml.evaluate_model(lr_model, X_test, y_test)\n",
    "#     print(\"Linear Regression Evaluation:\", lr_metrics)\n",
    "\n",
    "#     # Train and evaluate random forest model\n",
    "#     rf_model = ml.train_model('random_forest', X_train, y_train)\n",
    "#     rf_metrics = ml.evaluate_model(rf_model, X_test, y_test)\n",
    "#     print(\"Random Forest Evaluation:\", rf_metrics)\n",
    "\n",
    "#     # Save the models\n",
    "#     ml.save_model('linear_regression', 'models/linear_regression_model.pkl')\n",
    "#     ml.save_model('random_forest', 'models/random_forest_model.pkl')\n",
    "#     print(\"Models saved to 'models/linear_regression_model.pkl' and 'models/random_forest_model.pkl'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "def8fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "067f2471",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class MLTrainer:\n",
    "    def __init__(self):\n",
    "        self.models = {\n",
    "            'random_forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "        }\n",
    "        self.test_data_path = os.path.join(PROCESSED_DATA_DIR, 'test_data.csv')\n",
    "\n",
    "    def load_data(self):\n",
    "        return pd.read_csv(os.path.join(PROCESSED_DATA_DIR, 'preprocessed_network_data.csv'))\n",
    "\n",
    "    def split_data(self, data):\n",
    "        # Ensure all feature columns exist\n",
    "        X = data[[col for col in FEATURE_COLUMNS if col in data.columns]]\n",
    "        y = data[TARGET_COLUMN]\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Save test data\n",
    "        test_data = X_test.copy()\n",
    "        test_data[TARGET_COLUMN] = y_test\n",
    "        test_data.to_csv(self.test_data_path, index=False)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def train_models(self, X_train, y_train):\n",
    "        for name, model in self.models.items():\n",
    "            model.fit(X_train, y_train)\n",
    "            print(f\"Trained {name} model\")\n",
    "\n",
    "    def evaluate_models(self, X_test, y_test):\n",
    "        metrics = {}\n",
    "        for name, model in self.models.items():\n",
    "            y_pred = model.predict(X_test)\n",
    "            metrics[name] = {\n",
    "                'mae': mean_absolute_error(y_test, y_pred),\n",
    "                'rmse': np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "            }\n",
    "        return metrics\n",
    "\n",
    "    def save_models(self):\n",
    "        joblib.dump(self.models['random_forest'], RF_MODEL_PATH)\n",
    "        print(f\"Models saved to {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "662c14ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained random_forest model\n",
      "Evaluation Metrics: {'random_forest': {'mae': 2638940.9645060655, 'rmse': 3109255.0083593223}}\n",
      "Models saved to e:\\Mlop\\End to end\\real-time-video-optimizer\\models\n"
     ]
    }
   ],
   "source": [
    "# train_model.py\n",
    "# from model_training import MLTrainer  # Assuming your class is saved in model_training.py\n",
    "\n",
    "trainer = MLTrainer()\n",
    "\n",
    "# Step 1: Load data\n",
    "data = trainer.load_data()\n",
    "\n",
    "# Step 2: Split data\n",
    "X_train, X_test, y_train, y_test = trainer.split_data(data)\n",
    "\n",
    "# Step 3: Train model\n",
    "trainer.train_models(X_train, y_train)\n",
    "\n",
    "# Step 4: Evaluate model\n",
    "metrics = trainer.evaluate_models(X_test, y_test)\n",
    "print(\"Evaluation Metrics:\", metrics)\n",
    "\n",
    "# Step 5: Save model\n",
    "trainer.save_models()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c49e33ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    8.653000e+03\n",
      "mean     4.997107e+06\n",
      "std      2.859880e+06\n",
      "min      1.002330e+05\n",
      "25%      2.497430e+06\n",
      "50%      4.980944e+06\n",
      "75%      7.439378e+06\n",
      "max      9.999448e+06\n",
      "Name: actual_bandwidth, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(data['actual_bandwidth'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "917dfd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: 9726524.00, Predicted: 4113282.34\n",
      "Actual: 3910365.00, Predicted: 5117234.71\n",
      "Actual: 1876468.00, Predicted: 5539526.38\n",
      "Actual: 4760704.00, Predicted: 5797981.69\n",
      "Actual: 8184827.00, Predicted: 7536233.45\n",
      "Actual: 5089620.00, Predicted: 6419472.20\n",
      "Actual: 8809201.00, Predicted: 4004673.28\n",
      "Actual: 2781049.00, Predicted: 3027233.93\n",
      "Actual: 4760754.00, Predicted: 3718131.12\n",
      "Actual: 2844633.00, Predicted: 3553916.51\n"
     ]
    }
   ],
   "source": [
    "# Assuming your MLTrainer instance is named 'trainer'\n",
    "model = trainer.models['random_forest']  # get the random forest model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "for actual, pred in zip(y_test[:10], y_pred[:10]):\n",
    "    print(f\"Actual: {actual:.2f}, Predicted: {pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1ce80afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from config import *\n",
    "\n",
    "class MLTrainer:\n",
    "    def __init__(self):\n",
    "        self.model = RandomForestRegressor(\n",
    "            n_estimators=200,\n",
    "            max_depth=10,\n",
    "            min_samples_split=5,\n",
    "            random_state=42\n",
    "        )\n",
    "        self.test_data_path = os.path.join(PROCESSED_DATA_DIR, 'test_data.csv')\n",
    "        self.poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        self.target_transformed = False\n",
    "\n",
    "    def load_data(self):\n",
    "        return pd.read_csv(os.path.join(PROCESSED_DATA_DIR, 'preprocessed_network_data.csv'))\n",
    "\n",
    "    def split_data(self, data):\n",
    "        # Keep only available useful features\n",
    "        features = ['rtt', 'error_rate']\n",
    "        X = data[features]\n",
    "        y = data[TARGET_COLUMN]\n",
    "\n",
    "        # Apply log1p transform to target for stability\n",
    "        y = np.log1p(y)\n",
    "        self.target_transformed = True\n",
    "\n",
    "        # Add polynomial interaction terms\n",
    "        X_poly = self.poly.fit_transform(X)\n",
    "        feature_names = self.poly.get_feature_names_out(features)\n",
    "        X_poly_df = pd.DataFrame(X_poly, columns=feature_names)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X_poly_df, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        # Save test data\n",
    "        test_data = X_test.copy()\n",
    "        test_data[TARGET_COLUMN] = y_test\n",
    "        test_data.to_csv(self.test_data_path, index=False)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def train_model(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        print(\"âœ… Random Forest model trained\")\n",
    "\n",
    "    def evaluate_model(self, X_test, y_test):\n",
    "        y_pred = self.model.predict(X_test)\n",
    "\n",
    "        # Reverse log1p transform\n",
    "        if self.target_transformed:\n",
    "            y_test = np.expm1(y_test)\n",
    "            y_pred = np.expm1(y_pred)\n",
    "\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "        print(f\"ðŸ“Š Evaluation - MAE: {mae:.2f}, RMSE: {rmse:.2f}\")\n",
    "        return {'mae': mae, 'rmse': rmse}\n",
    "\n",
    "    def save_model(self):\n",
    "        joblib.dump(self.model, RF_MODEL_PATH)\n",
    "        print(f\"ðŸ’¾ Model saved to: {RF_MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "27e43b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Random Forest model trained\n",
      "ðŸ“Š Evaluation - MAE: 2658965.94, RMSE: 3161546.62\n",
      "ðŸ’¾ Model saved to: e:\\Mlop\\End to end\\real-time-video-optimizer\\models\\random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "trainer = MLTrainer()\n",
    "\n",
    "data = trainer.load_data()\n",
    "X_train, X_test, y_train, y_test = trainer.split_data(data)\n",
    "\n",
    "trainer.train_model(X_train, y_train)\n",
    "metrics = trainer.evaluate_model(X_test, y_test)\n",
    "trainer.save_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d47b913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
